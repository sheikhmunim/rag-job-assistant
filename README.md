# ğŸ§  Job Application RAG Assistant

A **Retrieval-Augmented Generation (RAG)** system that helps you craft tailored **CVs, cover letters, and interview answers** for AI/ML roles using your personal project documents and resumes as context.  
Built with **LangChain**, **Ollama (Llama 3.2:3B)**, and **Streamlit** â€” this assistant runs entirely **locally**, no external API needed.

## ğŸš€ Features

- ğŸ“‚ **Document ingestion** â€“ Upload and index your resumes, project summaries, and portfolios  
- ğŸ” **Vector-based retrieval** â€“ Context-aware search using **ChromaDB**  
- ğŸ§© **LLM-powered reasoning** â€“ Uses **Llama 3.2 (3B)** via Ollama for smart, offline generation  
- ğŸ’¬ **Interactive Q&A** â€“ Ask job-specific questions and get personalized answers  
- ğŸ–¥ï¸ **Streamlit interface** â€“ Simple UI for interacting with your assistant  
- ğŸ“˜ **Jupyter support** â€“ Test, debug, or fine-tune responses directly in notebooks  

## ğŸ§° Tech Stack

| Component     | Description                          |
|---------------|--------------------------------------|
| **Ollama**    | Local LLM runner (Llama 3.2:3B)      |
| **LangChain** | RAG pipeline & prompt management     |
| **ChromaDB**  | Vector database for semantic search  |
| **Streamlit** | Web UI for user interaction          |
| **Python**    | Core logic and orchestration         |
| **Jupyter**   | Experimentation & development        |

## ğŸ“ Directory Structure

```
project_root/
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ chroma_db/          # Vector database storage
â”‚   â”œâ”€â”€ sample/             # Sample documents
â”‚   â””â”€â”€ job_rag/
â”‚       â””â”€â”€ profile_docs/   # User resumes, project files
â”‚
â”œâ”€â”€ notebooks/              # Jupyter notebooks for testing
â”œâ”€â”€ app/                    # Streamlit app (main interface)
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ README.md
â””â”€â”€ .gitignore
```

## âš™ï¸ Setup Instructions

### 1ï¸âƒ£ Clone the repository
```bash
git clone https://github.com/sheikhmunim/job_application_rag.git
cd job_application_rag
```

### 2ï¸âƒ£ Create a virtual environment
```bash
python -m venv venv
source venv/bin/activate   # on Mac/Linux
venv\Scripts\activate      # on Windows
```

### 3ï¸âƒ£ Install dependencies
```bash
pip install -r requirements.txt
```

### 4ï¸âƒ£ Install and start Ollama
```bash
# Download Ollama: https://ollama.ai/download
ollama pull llama3.2:3b
ollama serve
```

### 5ï¸âƒ£ Run the app
```bash
streamlit run app/main.py
```

## ğŸ§© Environment Variables

| Variable        | Default                   | Description                      |
|-----------------|---------------------------|----------------------------------|
| `OLLAMA_HOST`   | `http://localhost:11434`  | Local Ollama server endpoint     |
| `MODEL_NAME`    | `llama3.2:3b`             | Model used for generation        |
| `DATA_DIR`      | `./data/sample`           | Input data directory             |
| `DB_DIR`        | `./data/chroma_db`        | Chroma database path             |

## ğŸ§  Example Queries

- â€œGenerate a cover letter for a Machine Learning Engineer role at Canva.â€  
- â€œSummarize my experience with ROS2 and PDDL planning.â€  
- â€œWrite a professional email to apply for an AI Engineer internship.â€  

## ğŸ§‘â€ğŸ’» Development Notes

- Jupyter notebooks can be used to prototype and test RAG chains.  
- Streamlit is used for deployment-ready interactive UI.  
- All data stays local â€” **no cloud APIs required**.  

## ğŸªª License

This project is released under the **MIT License** â€” free to use and modify with attribution.

## âœ¨ Author

**Sheikh Abdul Munim**  
Master of Artificial Intelligence, RMIT University  
ğŸ”— [LinkedIn](https://www.linkedin.com/in/sheikh-abdul-munim-b19391158/)  
ğŸ”— [GitHub](https://github.com/sheikhmunim)
